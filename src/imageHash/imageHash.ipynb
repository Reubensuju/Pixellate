{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n",
      "Checking video1.mp4\n",
      "Checking video10.mp4\n",
      "Checking video11.mp4\n",
      "Checking video12.mp4\n",
      "Checking video13.mp4\n",
      "Checking video14.mp4\n",
      "Checking video15.mp4\n",
      "Checking video16.mp4\n",
      "Checking video17.mp4\n",
      "Checking video18.mp4\n",
      "Checking video19.mp4\n",
      "Checking video2.mp4\n",
      "Checking video20.mp4\n",
      "Checking video3.mp4\n",
      "Checking video4.mp4\n",
      "Checking video5.mp4\n",
      "Checking video6.mp4\n",
      "Checking video7.mp4\n",
      "Checking video8.mp4\n",
      "Checking video9.mp4\n",
      "The query video is most likely from: video7.mp4\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import os\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import concurrent.futures\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    \"\"\" Extracts a fixed number of frames evenly spaced from a video. \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit loop if no more frames are available\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def calculate_hashes(frames):\n",
    "    \"\"\" Calculate perceptual hash for each frame. \"\"\"\n",
    "    return [imagehash.average_hash(Image.fromarray(frame)) for frame in frames]\n",
    "\n",
    "def compare_hashes(query_hashes, candidate_hashes):\n",
    "    \"\"\" Compare hashes from the query video to hashes from one candidate video using optimized numpy operations. \"\"\"\n",
    "    n = len(query_hashes)\n",
    "    min_diff = float('inf')\n",
    "\n",
    "    # Convert imagehash objects to NumPy arrays of the entire list\n",
    "    query_hashes_np = np.stack([np.array(h.hash, dtype=int) for h in query_hashes])\n",
    "    candidate_hashes_np = np.stack([np.array(h.hash, dtype=int) for h in candidate_hashes])\n",
    "\n",
    "    # Calculate the windowed sum of differences over all possible subarrays of length n\n",
    "    for offset in range(len(candidate_hashes) - n + 1):\n",
    "        # Select the window segment of candidate hashes\n",
    "        window = candidate_hashes_np[offset:offset + n]\n",
    "        # Calculate the number of different bits (hamming distance) using XOR and sum\n",
    "        current_diff = np.sum(query_hashes_np != window)\n",
    "        if current_diff < min_diff:\n",
    "            min_diff = current_diff\n",
    "\n",
    "    return min_diff\n",
    "\n",
    "\n",
    "def find_source_video(query_video_path):\n",
    "    query_frames = extract_frames(query_video_path)\n",
    "    query_hashes = calculate_hashes(query_frames)\n",
    "\n",
    "    print(len(query_frames))\n",
    "    print(len(query_hashes))\n",
    "\n",
    "    json_file_path = 'perceptualHash.json'  # Specify your file path here\n",
    "\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        precomputed_hashes = json.load(file)\n",
    "\n",
    "    best_match = None\n",
    "    smallest_diff = float('inf')\n",
    "\n",
    "    # Compare the query hashes against each candidate video's hashes in the JSON file\n",
    "    for video_file, candidate_hash_strings in precomputed_hashes.items():\n",
    "        print(\"Checking \" + video_file)\n",
    "        candidate_hashes = [imagehash.hex_to_hash(h_str) for h_str in candidate_hash_strings]\n",
    "\n",
    "        # Compare hashes to find the best match\n",
    "        diff = compare_hashes(query_hashes, candidate_hashes)\n",
    "        if diff < smallest_diff:\n",
    "            smallest_diff = diff\n",
    "            best_match = video_file\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "\n",
    "# videos_folder = '../../dataset/originals'\n",
    "query_video_path = '../../dataset/Tests/video7_1_modified.mp4'\n",
    "source_video = find_source_video(query_video_path)\n",
    "print(f\"The query video is most likely from: {source_video}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
