{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def calculate_optical_flow(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flows = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        flows.append(flow)\n",
    "        prev_gray = gray\n",
    "    \n",
    "    cap.release()\n",
    "    return flows\n",
    "\n",
    "def compute_mbh(flows):\n",
    "    mbhs = []\n",
    "\n",
    "    for flow in flows:\n",
    "        mbhs = []\n",
    "\n",
    "    for flow in flows:\n",
    "        flow_x, flow_y = cv2.split(flow)\n",
    "        grad_x_x = cv2.Sobel(flow_x, cv2.CV_32F, 1, 0, ksize=5)\n",
    "        grad_x_y = cv2.Sobel(flow_x, cv2.CV_32F, 0, 1, ksize=5)\n",
    "        grad_y_x = cv2.Sobel(flow_y, cv2.CV_32F, 1, 0, ksize=5)\n",
    "        grad_y_y = cv2.Sobel(flow_y, cv2.CV_32F, 0, 1, ksize=5)\n",
    "\n",
    "        mag_x, angle_x = cv2.cartToPolar(grad_x_x, grad_x_y, angleInDegrees=True)\n",
    "        mag_y, angle_y = cv2.cartToPolar(grad_y_x, grad_y_y, angleInDegrees=True)\n",
    "\n",
    "        # Ensure data is in the correct type\n",
    "        angle_x = np.float32(angle_x)\n",
    "        angle_y = np.float32(angle_y)\n",
    "\n",
    "        # Histogram bins and ranges\n",
    "        bins = [360]\n",
    "        range_hist = [0, 360]\n",
    "\n",
    "        hist_x = cv2.calcHist([angle_x], [0], None, bins, range_hist)\n",
    "        hist_y = cv2.calcHist([angle_y], [0], None, bins, range_hist)\n",
    "\n",
    "        # Flatten and concatenate histograms\n",
    "        mbh = np.concatenate((hist_x.flatten(), hist_y.flatten()))\n",
    "        mbhs.append(mbh)\n",
    "    \n",
    "    return np.array(mbhs)\n",
    "\n",
    "\n",
    "input_video_path = 'dataset/originals/joker.mp4'\n",
    "\n",
    "input_flows = calculate_optical_flow(input_video_path)\n",
    "input_mbhs = compute_mbh(input_flows)\n",
    "print(input_mbhs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(input_mbhs, query_mbhs):\n",
    "    distance, path = fastdtw(input_mbhs, query_mbhs, dist=euclidean)\n",
    "    # Finding the earliest point in the input sequence that aligns with the start of the query\n",
    "    start_frame = min([input_index for input_index, query_index in path if query_index == 0])\n",
    "    return start_frame\n",
    "\n",
    "def find_best_window_match(input_mbhs, query_mbhs):\n",
    "    min_distance = float('inf')\n",
    "    best_start = 0\n",
    "    window_size = len(query_mbhs)\n",
    "    \n",
    "    for start in range(len(input_mbhs) - window_size + 1):\n",
    "        print(start)\n",
    "        distance, _ = fastdtw(input_mbhs[start:start + window_size], query_mbhs, dist=euclidean)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_start = start\n",
    "            \n",
    "    return best_start\n",
    "\n",
    "def frame_to_timestamp(frame_index, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    seconds = frame_index / fps\n",
    "    return f\"{int(seconds // 3600):02}:{int((seconds % 3600) // 60):02}:{seconds % 60:.3f}\"\n",
    "\n",
    "query_video_path = 'dataset/queries/joker_query3.mp4'\n",
    "\n",
    "query_flows = calculate_optical_flow(query_video_path)\n",
    "query_mbhs = compute_mbh(query_flows)\n",
    "print(query_mbhs)\n",
    "\n",
    "starting_frame = find_best_window_match(input_mbhs, query_mbhs)\n",
    "start_timestamp = frame_to_timestamp(starting_frame, input_video_path)\n",
    "\n",
    "print(f\"Query video starts at frame {starting_frame}, which corresponds to timestamp {start_timestamp}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
